{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Web Scraping + File I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instructions: \n",
    "\n",
    "1. Go to https://polisci.wustl.edu/people/88/all OR https://polisci.wustl.edu/people/list/88/all\n",
    "2. Go to the page for each of the professors.\n",
    "3. Create a `.csv`` file with the following information for each professor:\n",
    "\t- Name\n",
    "\t- Title\n",
    "\t- E-mail\n",
    "\t- Web page\n",
    "\t- Specialization  \n",
    "\t\t- If they do not have a specialization, you can leave it blank. \n",
    "\t\t- An example from Deniz's page: https://polisci.wustl.edu/people/deniz-aksoy\n",
    "\t\t- Professor Aksoyâ€™s research is motivated by an interest in comparative political institutions and political violence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import urllib.request\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "names, emails, titles, web_pages, specializations = [], [], [], [], []\n",
    "url = 'https://polisci.wustl.edu/people/88/all'\n",
    "\n",
    "service = Service('/usr/bin/chromedriver')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get(url)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")  \n",
    "time.sleep(5)\n",
    "page_source = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "links = soup.find_all('a', href=True)\n",
    "prof_links = [link['href'] for link in links if bool(re.search(r'/people/\\b[a-z]+-[a-z]+\\b',link['href']))]\n",
    "\n",
    "for prof_link in prof_links:\n",
    "    prof_url = 'https://polisci.wustl.edu' + prof_link\n",
    "    prof_web_page = urllib.request.urlopen(prof_url)\n",
    "    prof_soup = BeautifulSoup(prof_web_page.read())\n",
    "\n",
    "    name = prof_soup.find('meta', property='og:title')['content']\n",
    "    title = prof_soup.find('div', class_='title').get_text()\n",
    "    email = prof_soup.find('a', href=lambda href: href and href.startswith('mailto:'))['href'][7:]\n",
    "\n",
    "    web_page_url = \"\"\n",
    "    try:\n",
    "        ul_tag = prof_soup.find('ul', class_='links')\n",
    "        web_page_url = ul_tag.find('li').find('a')['href']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    specialization = [] \n",
    "    try:\n",
    "        ul_tag = prof_soup.find('ul', class_=\"interests\")\n",
    "        interests = ul_tag.find_all('li')\n",
    "        for interest in interests:\n",
    "            specialization.append(re.sub(r'[\\n]+','',interest.get_text()).strip())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    names.append(name)\n",
    "    titles.append(title)\n",
    "    emails.append(email)\n",
    "    web_pages.append(web_page_url)\n",
    "    specializations.append(specialization)\n",
    "\n",
    "df = pd.DataFrame({'name': names,\n",
    "                   'title': titles,\n",
    "                   'emails': emails,\n",
    "                   'web_page': web_pages,\n",
    "                   'specialization': specializations})\n",
    "\n",
    "df.to_csv(\"wustl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
